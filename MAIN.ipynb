{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f8b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp import MLP\n",
    "from train_test import train_model, test_model\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad09dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/release/native/' # '../data/release/template/' for template space prediction\n",
    "task = 'scan_age' # 'birth_age' for birth age prediction\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 2000\n",
    "patience = 200 # for early stopping\n",
    "lr = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45459d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = np.loadtxt(task + '_train.txt', dtype='str')\n",
    "val_ids = np.loadtxt(task + '_validation.txt', dtype='str')\n",
    "test_ids = np.loadtxt(task + '_test.txt', dtype='str')\n",
    "\n",
    "mirror_index = np.load('mirror_index.npy') # mirrors right hemispheres to match with left hemispheres\n",
    "\n",
    "df = pd.read_csv(\"combined.csv\")\n",
    "\n",
    "df.insert(0, \"ID\", \"sub-\" + df[\"participant_id\"] + \"_\" + \"ses-\" + df[\"session_id\"].apply(str))\n",
    "df.drop(\"participant_id\", axis=1, inplace=True)\n",
    "df.drop(\"session_id\", axis=1, inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5723ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_path, task, ids):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for _id in ids:\n",
    "        try:\n",
    "            img_L = nib.load(data_path + _id + '_left.shape.gii')\n",
    "            x_L = np.stack(img_L.agg_data(), axis=1)\n",
    "            for i in range(4):\n",
    "                # replaces the zeros of the medial wall cut area with mean values\n",
    "                x_L[:, i][x_L[:, i] == 0] = np.mean(x_L[:, i][x_L[:, i] != 0])\n",
    "            xs.append(x_L.astype(np.float32))\n",
    "            y = np.array([df.loc[df['ID'] == _id, task].item()])\n",
    "            ys.append(y.astype(np.float32))\n",
    "            img_R = nib.load(data_path + _id + '_right.shape.gii')\n",
    "            x_R = np.stack(img_R.agg_data(), axis=1)[mirror_index] # mirroring\n",
    "            for i in range(4):\n",
    "                # replaces the zeros of the medial wall cut area with mean values\n",
    "                x_R[:, i][x_R[:, i] == 0] = np.mean(x_R[:, i][x_R[:, i] != 0])\n",
    "            xs.append(x_R.astype(np.float32))\n",
    "            y = np.array([df.loc[df['ID'] == _id, task].item()])\n",
    "            ys.append(y.astype(np.float32))\n",
    "        except:\n",
    "            print('train set element %s does not exist' % _id)\n",
    "    return xs, ys\n",
    "\n",
    "train_xs, train_ys = get_data(data_path, task, train_ids)\n",
    "val_xs, val_ys = get_data(data_path, task, val_ids)\n",
    "test_xs, test_ys = get_data(data_path, task, test_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6054185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data standardization\n",
    "\n",
    "train_xs = np.transpose(train_xs, axes=[1, 2, 0])\n",
    "means  = np.mean(np.mean(train_xs, axis=2), axis=0) # means of the 4 channels in the train set\n",
    "stds  = np.std(np.std(train_xs, axis=2), axis=0) # stds of the 4 channels in the train set\n",
    "train_xs = (train_xs - means.reshape(1, means.shape[0], 1)) / stds.reshape(1, means.shape[0], 1)\n",
    "train_xs = np.transpose(train_xs, axes=[2, 0, 1])\n",
    "\n",
    "val_xs = np.transpose(val_xs, axes=[1, 2, 0])\n",
    "val_xs = (val_xs - means.reshape(1, means.shape[0], 1)) / stds.reshape(1, means.shape[0], 1)\n",
    "val_xs = np.transpose(val_xs, axes=[2, 0, 1])\n",
    "\n",
    "test_xs = np.transpose(test_xs, axes=[1, 2, 0])\n",
    "test_xs = (test_xs - means.reshape(1, means.shape[0], 1)) / stds.reshape(1, means.shape[0], 1)\n",
    "test_xs = np.transpose(test_xs, axes=[2, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6197f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = [(torch.from_numpy(x), torch.from_numpy(y)) for x, y in zip(train_xs, train_ys)]\n",
    "\n",
    "val_subset = [(torch.from_numpy(x), torch.from_numpy(y)) for x, y in zip(val_xs, val_ys)]\n",
    "\n",
    "test_subset = [(torch.from_numpy(x), torch.from_numpy(y)) for x, y in zip(test_xs, test_ys)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3615f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_subset, batch_size=len(val_subset), shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_subset, batch_size=len(test_subset), shuffle=False)\n",
    "\n",
    "model = MLP(4, [16, 16, 16, 16], 1, device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "print(model)\n",
    "print('Number of parameters: ', sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58185799",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "\n",
    "best_val_index = -1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_model(train_loader, model, optimizer).cpu().detach().numpy()\n",
    "    val_loss = test_model(val_loader, model).cpu().detach().numpy()\n",
    "    test_loss = test_model(test_loader, model).cpu().detach().numpy()\n",
    "    new_min = \" \"\n",
    "    if epoch > 0:\n",
    "        if val_losses[best_val_index] > val_loss:\n",
    "            new_min = \"*\"\n",
    "            best_val_index = epoch\n",
    "            torch.save(model.state_dict(), 'MLP_paper.pt')\n",
    "        # early stopping is called\n",
    "        if len(val_losses) - best_val_index > patience:\n",
    "            print (\"Early stopping, best val loss and index:\")\n",
    "            print(val_losses[best_val_index], best_val_index)\n",
    "            break\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    print(new_min, \"Epoch: %d, train loss: %1.3f, val loss: %1.3f, test loss: %1.3f\" % (epoch, train_loss, val_loss, test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb1c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.plot(test_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fa823a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
